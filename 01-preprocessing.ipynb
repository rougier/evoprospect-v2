{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ca3fea",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Preprocessing\n",
    "**Copyright 2023 (c) Naomi Chaix-Echel & Nicolas P Rougier**  \n",
    "Released under a BSD 2-clauses license\n",
    "\n",
    "This notebook reads and process the original dataset to ensure that tasks are named properly.\n",
    "The original dataset is untouched and the processed dataset is saved using an alternative filename.\n",
    "\n",
    "| Name           | Type     | Signification                 |\n",
    "| :------------- | :------- | :---------------------------- |\n",
    "| **subject_id** | string   | Identification of the subject |\n",
    "| **date**       | datetime | Date whe then trial was made   | \n",
    "| **task_id**    | integer  | Identification of the task    | \n",
    "| **P_left**     | float    | Reward probability of the left stimulus |\n",
    "| **V_left**     | float    | Reward amount of the left stimulus |\n",
    "| **P_right**    | float    | Reward probability of the right stimulus |\n",
    "| **P_right**    | float    | Reward amount of the right stimulus |\n",
    "| **response**   | int      | Response (0: left, 1: right) |\n",
    "| **reward**     | int      | Reward delivered (1) or not (0) |\n",
    "| **RT**         | int      | Response time (ms) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02dcee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Lottery description\n",
    "\n",
    "For all the following types of lottery, we consider a choice between (x1, p1) and (x2, p2), xi being the value and pi being the probability:\n",
    "* xi can be positive, null or negative: -3, -2, -1, 0, +1, +2, +3\n",
    "* pi can be: 0.25, 0.50, 0.75 or 1.00\n",
    "\n",
    "\n",
    "### Type 1 : x1 > 0 and x2 < 0, p1 = p2\n",
    "\n",
    "* Lottery pairs containing one lottery with potential losses (LPL) and on lottery with potential gains (LPG)\n",
    "* assess the discrimination of losses from the gains\n",
    "* 36 different lottery pairs.\n",
    "\n",
    "### Type 2 : p1 = p2 and x1 > x2 > 0\n",
    "\n",
    "* LPG with a stochastic dominant option differentiating only by the x values\n",
    "* assess the discrimination of positive x-values\n",
    "* 12 different lottery pairs\n",
    "\n",
    "### Type 3 : p1 = p2 and x1 < x2 < 0\n",
    "\n",
    "* LPL with a stochastic dominant option differentiating only by the x values;\n",
    "* assess the discrimination of negative x-values\n",
    "* 12 different lottery pairs\n",
    "\n",
    "### Type 4 : p1 > p2 and x1 = x2 > 0\n",
    "\n",
    "* LPG with a stochastic dominant option differentiating only by the p values\n",
    "* assess the discrimination of p-values associated to positive x-values\n",
    "* 12 different lottery pairs \n",
    "\n",
    "### Type 5 : p1 < p2 and x1 = x2 < 0\n",
    "\n",
    "* LPL with a stochastic dominant option differentiating only by the p values\n",
    "* assess the discrimination of probabilities associated to negative quantities\n",
    "* 18 different lottery pairs\n",
    "\n",
    "### Type 6 : p1 < p2 and x1 > x2 > 0\n",
    "\n",
    "* LPG with no stochastic dominant option\n",
    "* 18 different lottery pairs.\n",
    "\n",
    "### Type 7 : p1 < p2 and x1 < x2 < 0\n",
    "\n",
    "* LPL with no stochastic dominant option\n",
    "* 18 different lottery pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f00ec",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030c059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime                 # Time operations\n",
    "import numpy as np              # Array operations\n",
    "import pandas as pd             # Database operations\n",
    "import matplotlib.pyplot as plt # Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82059c3c-4551-411e-8621-8eea953ce4aa",
   "metadata": {},
   "source": [
    "## Importer la page de fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd21005d-72e1-43a2-a8fa-9a27f19bb0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"00-common.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c73b9",
   "metadata": {},
   "source": [
    "## Load and Fusion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09675e12-5a65-4247-96c0-7194e52e8f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data... \", end=\"\")\n",
    "\n",
    "# Liste des noms de fichiers à charger et fusionner\n",
    "files_to_concat = [\"./data/ECO/Abricot.csv\", \"./data/ECO/Alaryc.csv\", \"./data/ECO/Alvin.csv\", \"./data/ECO/Anubis.csv\", \"./data/ECO/Barnabé.csv\", \"./data/ECO/César.csv\", \n",
    "                  \"./data/ECO/Dory.csv\", \"./data/ECO/Eric.csv\", \"./data/ECO/Ficelle.csv\", \"./data/ECO/Gaia.csv\", \"./data/ECO/Havanna.csv\", \"./data/ECO/Gandhi.csv\", \n",
    "                  \"./data/ECO/Hercules.csv\", \"./data/ECO/Horus.csv\", \"./data/ECO/Iron.csv\", \"./data/ECO/Jeanne.csv\", \"./data/ECO/Joy.csv\", \"./data/ECO/Lassa.csv\", \n",
    "                  \"./data/ECO/Néma.csv\", \"./data/ECO/Néréis.csv\", \"./data/ECO/Olaf.csv\", \"./data/ECO/Olga.csv\", \"./data/ECO/Olli.csv\", \"./data/ECO/Patchouli.csv\", \n",
    "                  \"./data/ECO/Patsy.csv\", \"./data/ECO/Yin.csv\", \"./data/ECO/Yoh.csv\", \"./data/ECO/Bérénice.csv\"]\n",
    "\n",
    "# Charger chaque fichier CSV dans un DataFrame\n",
    "dataframe = [pd.read_csv(filename, sep=\",\", decimal=',') for filename in files_to_concat]\n",
    "\n",
    "# Concaténer les lignes des DataFrames\n",
    "original_data = pd.concat(dataframe, ignore_index=True)\n",
    "\n",
    "# Sauvegarder le résultat dans un nouveau fichier CSV\n",
    "original_data.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "#Enlever les lignes des taches ECO_T (phase d'entrainement), Lot11 (tâches plus complexes) et ECO2 (affichage des options différent)\n",
    "original_data = original_data[~original_data['tache'].str.contains(\"ECO_T|Lot11|ECO2\")]\n",
    "\n",
    "print(\"done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741c7ce4-d01d-40a5-8d93-298bbb51e955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abricot' 'Alaryc' 'Alvin' 'Anubis' 'Barnabé' 'César' 'Dory' 'Eric'\n",
      " 'Ficelle' 'Gandhi' 'Hercules' 'Horus' 'Jeanne' 'Lassa' 'Néma' 'Néréis'\n",
      " 'Olaf' 'Olga' 'Olli' 'Patchouli' 'Patsy' 'Yin' 'Yoh' 'Bérénice']\n"
     ]
    }
   ],
   "source": [
    "print(original_data[\"nom_singe\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9c0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = \"./data/data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28eebfd",
   "metadata": {},
   "source": [
    "## Filter, rename & retype fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ea4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant fields\n",
    "data = original_data[[\"date_debut\",\n",
    "                      \"heure_debut\",\n",
    "                      \"nom_singe\",\n",
    "                      \"tache\",\n",
    "                      \"palier\",\n",
    "                      \"r1_stim_a\",\n",
    "                      \"r2_stim_a\",\n",
    "                      \"p2_stim_a\",\n",
    "                      \"r1_stim_b\",\n",
    "                      \"r2_stim_b\",\n",
    "                      \"p2_stim_b\",\n",
    "                      \"id_stim_a\",\n",
    "                      \"id_stim_b\",\n",
    "                      \"stim_a_x\",\n",
    "                      \"stim_a_y\",\n",
    "                      \"stim_b_x\",\n",
    "                      \"stim_b_y\",\n",
    "                      \"stim_choisi\",\n",
    "                      \"resultat\",\n",
    "                      \"recompense\",\n",
    "                      \"temps_demarrage\",\n",
    "                      \"temps_reponse\",\n",
    "                      \"id_module\"]].copy()\n",
    "\n",
    "# Rename fields\n",
    "data = data.rename(columns={\"nom_singe\"      :    \"subject_id\",\n",
    "                            \"date_debut\"     :    \"date\",\n",
    "                            \"tache\"          :    \"task_id\",\n",
    "                            \"r1_stim_a\" :    \"V1_left\",\n",
    "                            \"r2_stim_a\" :    \"V2_left\",\n",
    "                            \"p2_stim_a\" :    \"P2_left\",\n",
    "                            \"r1_stim_b\" :    \"V1_right\",\n",
    "                            \"r2_stim_b\" :    \"V2_right\",\n",
    "                            \"p2_stim_b\" :    \"P2_right\",\n",
    "                            \"id_stim_a\":    \"id_stim_gauche\",\n",
    "                            \"id_stim_b\":    \"id_stim_droite\",\n",
    "                            \"stim_a_x\"  :    \"stim_gauche_x\",\n",
    "                            \"stim_a_y\"  :    \"stim_gauche_y\",\n",
    "                            \"stim_b_x\"  :    \"stim_droite_x\",\n",
    "                            \"stim_b_y\"  :    \"stim_droite_y\",\n",
    "                            \"temps_reponse\"  :    \"RT\",\n",
    "                            \"temps_demarrage\":    \"ST\"})\n",
    "\n",
    "noms_a_remplacer = [\"Barnabé\", \"Néréis\", \"Néma\", \"César\", \"Bérénice\"]\n",
    "noms_remplaces = [\"Barnabe\", \"Nereis\", \"Nema\", \"Cesar\", \"Berenice\"]\n",
    "\n",
    "data = data[~data['subject_id'].str.contains(\"Test_Id3|Test_Saumon|Baal|Anyanka|Yelena|Eowyn|Samael|Natasha\")]\n",
    "\n",
    "# Remplacez les noms dans la colonne \"subject_id\"\n",
    "data['subject_id'] = data['subject_id'].replace(noms_a_remplacer, noms_remplaces, regex=True)\n",
    "\n",
    "\n",
    "# Convertir les colonnes P2_left et P2_right en numériques\n",
    "data['P2_left'] = pd.to_numeric(data['P2_left'], errors='coerce')\n",
    "data['P2_right'] = pd.to_numeric(data['P2_right'], errors='coerce')\n",
    "\n",
    "\n",
    "# Ajouter les colonnes P1_left et P1_right\n",
    "data['P1_left'] = 1 - data['P2_left']\n",
    "data['P1_right'] = 1 - data['P2_right']\n",
    "\n",
    "data[\"EV_left\"] = data[\"V1_left\"] * data[\"P1_left\"] + data[\"V2_left\"] * data[\"P2_left\"]\n",
    "data[\"EV_right\"] = data[\"V1_right\"] * data[\"P1_right\"] + data[\"V2_right\"] * data[\"P2_right\"]\n",
    "\n",
    "# Convert date type (from string to datetime64)\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441ccced-122d-433e-bbca-b5fe2064b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abricot' 'Alaryc' 'Alvin' 'Anubis' 'Barnabe' 'Cesar' 'Dory' 'Eric'\n",
      " 'Ficelle' 'Gandhi' 'Hercules' 'Horus' 'Jeanne' 'Lassa' 'Nema' 'Nereis'\n",
      " 'Olaf' 'Olga' 'Olli' 'Patchouli' 'Patsy' 'Yin' 'Yoh' 'Berenice']\n"
     ]
    }
   ],
   "source": [
    "print(data[\"subject_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1032e26-5dae-46fa-bd1d-4be8efbcd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de remplacement\n",
    "remplacement = {\n",
    "    'Abricot': 'abr',\n",
    "    'Alaryc': 'ala',\n",
    "    'Alvin': 'alv',\n",
    "    'Anubis': 'anu',\n",
    "    'Barnabe': 'bar',\n",
    "    'Berenice': 'ber',\n",
    "    'Cesar': 'ces',\n",
    "    'Dory': 'dor',\n",
    "    'Eric': 'eri',\n",
    "    'Ficelle': 'fic',\n",
    "    'Hercules': 'her',\n",
    "    'Horus': 'hor',\n",
    "    'Lassa': 'las',\n",
    "    'Nema': 'nem',\n",
    "    'Nereis': 'ner',\n",
    "    'Olli': 'oll',\n",
    "    'Patchouli': 'pac',\n",
    "    'Patsy': 'pat',\n",
    "    'Yoh': 'yoh',\n",
    "    'Olaf' : 'ola',\n",
    "    'Yin' : 'yin',\n",
    "    'Jeanne' : 'jea',\n",
    "    'Olga' : 'olg',\n",
    "    'Gandhi' : 'gan'\n",
    "}\n",
    "\n",
    "# Remplacement des valeurs dans la colonne 'subject_id'\n",
    "data['subject_id'] = data['subject_id'].replace(remplacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93528cad",
   "metadata": {},
   "source": [
    "## Enrich data with actual gain or loss and subject's answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df880bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la colonne \"gain\"\n",
    "data['gain'] = data['recompense'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "# Ajouter la colonne \"loss\"\n",
    "data['loss'] = data['recompense'].apply(lambda x: x if x < 0 else 0)\n",
    "\n",
    "# Ajouter la colonne \"response\" correspond au choix de l'option\n",
    "data['response'] = data.apply(lambda row: 0 if row['stim_choisi'] == row['id_stim_gauche'] else (1 if row['stim_choisi'] == row['id_stim_droite'] else None), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4733f",
   "metadata": {},
   "source": [
    "## Assign task id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83683b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign task ids based on probablities and values\n",
    "p1, x1 = data[\"P1_left\"], data[\"V1_left\"]\n",
    "p2, x2 = data[\"P1_right\"], data[\"V1_right\"]\n",
    "\n",
    "data.loc[(p1 == p2) & (x1 == x2), \"task_id\"] = 0\n",
    "\n",
    "data.loc[(p1 == p2) & (x1 <  0) & (x2 >   0), \"task_id\"] = 1\n",
    "data.loc[(p1 == p2) & (x2 <  0) & (x1 >   0), \"task_id\"] = 1\n",
    "\n",
    "data.loc[(p1 == p2) & (x2 >  0) & (x1 >   x2), \"task_id\"] = 2\n",
    "data.loc[(p1 == p2) & (x1 >  0) & (x2 >   x1), \"task_id\"] = 2\n",
    "\n",
    "data.loc[(p1 == p2) & (x1 < x2) & (x2 < 0), \"task_id\"] = 3\n",
    "data.loc[(p1 == p2) & (x2 < x1) & (x1 < 0), \"task_id\"] = 3\n",
    "\n",
    "data.loc[(p1 >  p2) & (x1 >  0) & (x1 == x2), \"task_id\"] = 4\n",
    "data.loc[(p2 >  p1) & (x1 >  0) & (x1 == x2), \"task_id\"] = 4\n",
    "\n",
    "data.loc[(p1 >  p2) & (x1 <  0) & (x1 == x2), \"task_id\"] = 5\n",
    "data.loc[(p2 >  p1) & (x1 <  0) & (x1 == x2), \"task_id\"] = 5\n",
    "\n",
    "data.loc[(p1 <  p2) & (x1 > x2) & (x2 >   0), \"task_id\"] = 6\n",
    "data.loc[(p2 <  p1) & (x2 > x1) & (x1 >   0), \"task_id\"] = 6\n",
    "\n",
    "data.loc[(p1 <  p2) & (x1 < x2) & (x2 <   0), \"task_id\"] = 7\n",
    "data.loc[(p2 <  p1) & (x2 < x1) & (x1 <   0), \"task_id\"] = 7\n",
    "\n",
    "# Remplacer les noms des task_id restants\n",
    "data['task_id'] = data['task_id'].replace({'ECO_Lot1' : 11, 'ECO_Lot2' : 12, 'ECO_Lot3' : 13, 'ECO_Lot4' : 14, 'ECO_Lot5' : 15, 'ECO_Lot6' : 16, 'ECO_Lot7' : 17, 'ECO_Lot10' : 110, 'ECO_Lot11' : 111})\n",
    "# Convertir la colonne \"task_id\" en numérique\n",
    "data['task_id'] = data['task_id'].astype(int)\n",
    "\n",
    "\n",
    "# Il reste des tâches non attribuées -> à définir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91552d17-9f7a-4b41-873e-7b809b3f47e2",
   "metadata": {},
   "source": [
    "# Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c22482-6b6c-4d96-9853-489fd1bcb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [1, 2, 3, 4, 5, 6, 7]\n",
    "data = data[data[\"task_id\"].isin(tasks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73716a4e",
   "metadata": {},
   "source": [
    "## Save new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d365f218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving new dataset... done!\n",
      "New dataset: ./data/data-processed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filename, extension = os.path.splitext(data_filename)\n",
    "filename = f\"{filename}-processed{extension}\"\n",
    "\n",
    "print(\"Saving new dataset... \", end=\"\")\n",
    "data.to_csv(filename)\n",
    "print(\"done!\")\n",
    "print(\"New dataset:\", filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
